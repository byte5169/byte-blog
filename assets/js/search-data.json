{
  
    
        "post0": {
            "title": "Training a MNIST classifier",
            "content": "The work below is based on the chapter 4 of Deep learning for Coders with fastai and PyTorch and github repo dedicated to that chapter by asiedubrempong. . Will be using here fastai that is basically a high-level API for deep learning over PyTorch and easier to use. . I encourage you to use Google Colab for this project. . Below we are importing necessary libraries. I for some reason this cell gives you a mistake - uncomment the first line, restart your runtime and run it again. . import fastai from fastai.vision.all import * . Checking if fastai installed correctly. . fastai.__version__ . &#39;2.2.5&#39; . Fastai comes with a basic and most popular datasets to work with. Let&#39;s use that in our advantage and import MNIST dataset to our path. . path = untar_data(URLs.MNIST) . Let&#39;s see how MNIST dataset is structured. It is already broke down for us into training and testing dataset. Good. . path.ls() . (#2) [Path(&#39;/root/.fastai/data/mnist_png/training&#39;),Path(&#39;/root/.fastai/data/mnist_png/testing&#39;)] . Inside training dataset we can see folders with numbers from 0 to 10. . (path/&#39;training&#39;).ls().sorted() . (#10) [Path(&#39;/root/.fastai/data/mnist_png/training/0&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/1&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/2&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/3&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/4&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/5&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/6&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/7&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/8&#39;),Path(&#39;/root/.fastai/data/mnist_png/training/9&#39;)] . Let&#39;s look even closer into data and try to print out one digit. . fours = (path/&#39;training/4&#39;).ls() . img4_path = fours[1] #taking 1st index of data img4 = Image.open(img4_path) #using PIL to open image file img4 . To display how computer sees this image we need to use arrays or tensors. After we converted image to tensor we pack it into dataframe using Pandas library. If you are not using Gogle Colab, you will have to import it. . import pandas as pd . img4_t = tensor(img4) df = pd.DataFrame(img4_t) df.style.set_properties(**{&#39;font-size&#39;:&#39;6pt&#39;}).background_gradient(&#39;Greys&#39;) . 0 1 2 3 4 5 6 7 8 9 10 11 12 13 14 15 16 17 18 19 20 21 22 23 24 25 26 27 . 0 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 1 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 2 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 3 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 4 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 5 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 68 | 201 | 227 | 42 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 6 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 190 | 252 | 252 | 182 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 7 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 51 | 242 | 252 | 252 | 0 | 0 | 0 | 6 | 153 | 233 | 111 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 8 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 161 | 252 | 252 | 0 | 0 | 0 | 64 | 252 | 253 | 168 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 9 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 127 | 252 | 252 | 0 | 0 | 0 | 64 | 252 | 253 | 168 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 10 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 128 | 253 | 253 | 18 | 0 | 0 | 64 | 253 | 254 | 107 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 11 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 127 | 252 | 252 | 71 | 0 | 0 | 64 | 252 | 253 | 63 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 12 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 127 | 252 | 252 | 4 | 22 | 11 | 64 | 252 | 253 | 107 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 13 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 153 | 252 | 252 | 183 | 252 | 210 | 190 | 252 | 253 | 63 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 14 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 62 | 185 | 249 | 252 | 252 | 253 | 252 | 252 | 252 | 252 | 253 | 63 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 15 0 | 0 | 0 | 0 | 0 | 0 | 0 | 38 | 192 | 254 | 253 | 253 | 253 | 253 | 212 | 211 | 211 | 222 | 253 | 255 | 81 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 16 0 | 0 | 0 | 0 | 0 | 0 | 43 | 171 | 252 | 253 | 252 | 252 | 231 | 124 | 0 | 0 | 0 | 64 | 252 | 253 | 168 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 17 0 | 0 | 0 | 0 | 0 | 0 | 127 | 252 | 252 | 253 | 252 | 252 | 136 | 0 | 0 | 0 | 0 | 64 | 252 | 253 | 168 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 18 0 | 0 | 0 | 0 | 0 | 0 | 127 | 252 | 252 | 253 | 252 | 212 | 28 | 0 | 0 | 0 | 0 | 48 | 242 | 253 | 168 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 19 0 | 0 | 0 | 0 | 0 | 0 | 127 | 252 | 252 | 253 | 252 | 126 | 0 | 0 | 0 | 0 | 0 | 27 | 228 | 253 | 168 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 20 0 | 0 | 0 | 0 | 0 | 0 | 9 | 204 | 253 | 254 | 186 | 9 | 0 | 0 | 0 | 0 | 0 | 27 | 229 | 255 | 168 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 21 0 | 0 | 0 | 0 | 0 | 0 | 0 | 69 | 168 | 168 | 42 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 176 | 253 | 168 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 22 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 106 | 253 | 210 | 11 | 0 | 0 | 0 | 0 | 0 | 0 | . 23 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 35 | 253 | 252 | 21 | 0 | 0 | 0 | 0 | 0 | 0 | . 24 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 122 | 252 | 21 | 0 | 0 | 0 | 0 | 0 | 0 | . 25 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 26 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . 27 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | 0 | . Now we are collecting the paths to image folders into a dictionary. . path_len = len((path/&#39;training&#39;).ls()) paths = {i: [fn for fn in (path/f&#39;training/{i}&#39;).ls()] for i in range(path_len)} paths[0][:5] . [Path(&#39;/root/.fastai/data/mnist_png/training/0/22013.png&#39;), Path(&#39;/root/.fastai/data/mnist_png/training/0/59934.png&#39;), Path(&#39;/root/.fastai/data/mnist_png/training/0/55484.png&#39;), Path(&#39;/root/.fastai/data/mnist_png/training/0/37043.png&#39;), Path(&#39;/root/.fastai/data/mnist_png/training/0/9820.png&#39;)] . Converting images to tensors. . img_tensors = {key: [tensor(Image.open(path)) for path in paths] for (key, paths) in paths.items()} . Stacking tensors one on each other to get mean representation of what machine thinks is &quot;a mean number&quot;, so we could later compair single digit to the mean of that digit. . stacked_tensors = {key: torch.stack(imgs).float() / 255 for (key, imgs) in img_tensors.items()} . for _ , values in stacked_tensors.items(): print(values.shape) . torch.Size([5923, 28, 28]) torch.Size([6742, 28, 28]) torch.Size([5958, 28, 28]) torch.Size([6131, 28, 28]) torch.Size([5842, 28, 28]) torch.Size([5421, 28, 28]) torch.Size([5918, 28, 28]) torch.Size([6265, 28, 28]) torch.Size([5851, 28, 28]) torch.Size([5949, 28, 28]) . mean_tensors = {key: imgs.mean(0) for (key, imgs) in stacked_tensors.items()} . show_images(mean_tensors.values()) . Let&#39;s grab a single digit from stacked tensors and try to calculate the distance between it and other digits. For that we are writing function &#39;distance&#39; and &#39;is_3&#39; . Function &#39;distance&#39; calculates MAE. I encourage you to read more on the topic of MAE &amp; RMSE. . Then we compare our number a_3 to any other mean digit and produce the result if it is the number we are looking for. . a_3 = stacked_tensors[3][2] show_image(a_3) . &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f647c2f1ef0&gt; . def distance(a, b): return (a - b).abs().mean((-1, -2)) distance(a_3, mean_tensors[3]) . tensor(0.1192) . def is_3(x): return distance(x,mean_tensors[3]) &lt; distance(x,mean_tensors[4]) . is_3(a_3) . tensor(True) . Now we need to prepare data. We are splitting dataset into train/test, labeling targets and putting datasets into DataLoader. . def create_labels(rows, cols, index): labels = torch.zeros((rows, cols)) labels[:, index] = 1 return labels . test_paths = {i: [p for p in (path/f&#39;testing/{i}&#39;).ls()] for i in range(path_len)} test_stacked_tensors = {key: torch.stack([tensor(Image.open(path)) for path in paths]).float()/255 for (key, paths) in test_paths.items()} test_stacked_labels = {key: create_labels(tensors.shape[0], len(test_stacked_tensors), key) for key, tensors in test_stacked_tensors.items()} test_x = torch.cat([o for o in test_stacked_tensors.values()]).view(-1, 28*28) test_y = torch.cat([o for o in test_stacked_labels.values()]) . train_x = torch.cat([o for o in stacked_tensors.values()]).view(-1, 28*28) train_y = torch.cat([o for o in test_stacked_labels.values()]) . train_dataset = list(zip(train_x, train_y)) train_dl = DataLoader(train_dataset, batch_size=64, shuffle=True) test_dataset = list(zip(test_x, test_y)) test_dl = DataLoader(test_dataset, batch_size=64) . Defining our loss function that measures the distance between predictions and targets. We are using here the sigmoid function as it always outputs a number between 0 and 1, and we don&#39;t want it to be below 0. . def mnist_loss(xb, yb): xb = xb.sigmoid() return torch.where(yb==1, 1-xb, xb).mean() . Time to define basic steps for our model. . For more details please visit chapter 4 of the &#39;Deep learning for Coders with fastai and PyTorch&#39; book. . def init_params(size, std=1.0): return (torch.randn(size)*std).requires_grad_() . weights = init_params((28*28,10)) bias = init_params(1) . def linear1(xb): return xb@weights + bias . def calc_grad(xb, yb, model): preds = model(xb) loss = mnist_loss(preds, yb) loss.backward() . def train_epoch(model, lr, params): for xb,yb in train_dl: calc_grad(xb, yb, model) for p in params: p.data -= p.grad*lr p.grad.zero_() . def cal_accuracy(xb, yb): preds = xb.sigmoid() correct = (preds&gt;0.5) == yb return correct.float().mean() . def validate_epoch(model): accs = [cal_accuracy(model(xb), yb) for xb,yb in test_dl] return round(torch.stack(accs).mean().item(), 4) . Setting learning rate and parameters. . lr = 0.1 params = weights, bias . Let&#39;s see how it goes! . for i in range(20): train_epoch(linear1, lr, params) print(validate_epoch(linear1), end=&#39; &#39;) . 0.6658 0.7118 0.7424 0.7635 0.7809 0.7963 0.809 0.8233 0.8405 0.8574 0.8648 0.8689 0.8718 0.8738 0.8757 0.8771 0.8783 0.8794 0.8802 0.8811 . So we reached 88% accuracy using only math and some basic functions :) . But we could have done everything much simpler like that using inner tools of fastai and PyTorch: . dls = ImageDataLoaders.from_folder(path, train=&#39;training&#39;, valid=&#39;testing&#39;) learn = cnn_learner(dls, resnet18, pretrained=False, loss_func=F.cross_entropy, metrics=accuracy) learn.fit_one_cycle(1, 1e-3) . epoch train_loss valid_loss accuracy time . 0 | 0.069037 | 0.035452 | 0.988200 | 14:47 | .",
            "url": "https://byte5169.github.io/byte-blog/2021/01/16/Training-a-MNIST-classifier.html",
            "relUrl": "/2021/01/16/Training-a-MNIST-classifier.html",
            "date": " • Jan 16, 2021"
        }
        
    
  
    
        ,"post1": {
            "title": "My first post and about",
            "content": "Hello stranger, . This is a blog from a person who his whole life (around 25 years) was studying humanitarian sciences and now decided to drastically change his field of work. . The main goal of this blog is to follow my journey of Machine Learning and Deep Learning. . A bit of myself: . I&#39;m 31 as of 10.01.2021. . I do know 3 foreign languages (English, Swedish, Chinese), that is not including my two native languages. I have been working for a large IT company for the past 10 years on various positions. A month ago I had a chance to switch drastically my field of work from PM and PdM to more AI and ML field. . So as you may guess I have accepted this challenge and began to study ML from scratch I would say. I had some experience on coding before, but it was so long ago so basically I had to start all over again. . For the past month I have been learning various number of course from codeacademy, udemy, youtube, khanacademy, etc to gain a bit of basic coding knowledge and math at least. . Enough about me, some more on the blog topics. . About blog . This blog will contain all different kind of materials on ML, DL, math and everything that I will come across during my voyage. . To catch you up . The best resources I will be using here: . Python | PyTorch | TensorFlow | Scikit-learn | Fastai | AWS | Most of the things above I still haven&#39;t touched yet, and I will learn it and post my little experiments here. . Internet resourse: . Khanacademy for any learning math problems. | Kaggle best website if you want to look for datasets. | ML learning tree I have came across this one on the first week of learning and it blowed my mind. It was created by a great youtube person Daniel Bourke | I will try to post every week, summing up what have I learned, maybe with some fancy project based on the learnings. . PS. I&#39;m new to fastpages and github in general, so bear with me and my writings it will improve with time, I promise. .",
            "url": "https://byte5169.github.io/byte-blog/2021/01/10/My_First-Post-and-About.html",
            "relUrl": "/2021/01/10/My_First-Post-and-About.html",
            "date": " • Jan 10, 2021"
        }
        
    
  

  
  

  
      ,"page1": {
          "title": "About Me",
          "content": "I’m 31 as of 10.01.2021. . I do know 3 foreign languages (English, Swedish, Chinese), that is not including my two native languages. I have been working for a large IT company for the past 10 years on various positions. A month ago I had a chance to switch drastically my field of work from PM and PdM to more AI and ML field. . So as you may guess I have accepted this challenge and began to study ML from scratch I would say. I had some experience on coding before, but it was so long ago so basically I had to start all over again. .",
          "url": "https://byte5169.github.io/byte-blog/about/",
          "relUrl": "/about/",
          "date": ""
      }
      
  

  

  
  

  

  
  

  

  
  

  
  

  
  

  
      ,"page10": {
          "title": "",
          "content": "Sitemap: {{ “sitemap.xml” | absolute_url }} | .",
          "url": "https://byte5169.github.io/byte-blog/robots.txt",
          "relUrl": "/robots.txt",
          "date": ""
      }
      
  

}